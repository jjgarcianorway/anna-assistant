{
  "schema_version": "1.0.0",
  "last_updated": "2025-11-27",
  "notes": "Anna Model Registry - Updated by Claude periodically",

  "recommended_by_tier": {
    "datacenter": {
      "description": "80GB+ VRAM (A100/H100)",
      "senior": "qwen2.5:72b",
      "junior": "qwen3:8b"
    },
    "datacenter_entry": {
      "description": "32-48GB VRAM (A6000, dual GPUs)",
      "senior": "qwen3:32b",
      "junior": "qwen3:4b"
    },
    "high_end_gpu": {
      "description": "16-24GB VRAM (RTX 3090/4090)",
      "senior": "qwen3:14b",
      "junior": "qwen3:4b"
    },
    "mid_range_gpu": {
      "description": "6-12GB VRAM (RTX 3060/4060)",
      "senior": "qwen3:8b",
      "junior": "qwen3:1.7b"
    },
    "low_gpu": {
      "description": "<6GB VRAM",
      "senior": "qwen3:4b",
      "junior": "qwen3:0.6b"
    },
    "high_cpu": {
      "description": "32GB+ RAM, 8+ cores, no GPU",
      "senior": "qwen3:4b",
      "junior": "qwen3:1.7b"
    },
    "mid_cpu": {
      "description": "16GB+ RAM, 4+ cores",
      "senior": "qwen3:1.7b",
      "junior": "qwen3:0.6b"
    },
    "low_cpu": {
      "description": "<16GB RAM or <4 cores",
      "senior": "qwen3:0.6b",
      "junior": "qwen3:0.6b"
    }
  },

  "known_good_models": [
    "qwen3:0.6b",
    "qwen3:1.7b",
    "qwen3:4b",
    "qwen3:8b",
    "qwen3:14b",
    "qwen3:32b",
    "qwen3:30b-a3b",
    "qwen2.5:3b",
    "qwen2.5:7b",
    "qwen2.5:14b",
    "qwen2.5:32b",
    "qwen2.5:72b",
    "llama3.2:3b",
    "llama3.1:8b",
    "llama3.1:70b",
    "gemma3:1b",
    "gemma3:9b",
    "gemma3:27b",
    "gemma2:2b",
    "gemma2:9b",
    "gemma2:27b",
    "mistral:7b",
    "mistral:7b-instruct",
    "mixtral:8x7b",
    "deepseek-coder:6.7b",
    "deepseek-coder:33b",
    "phi3:mini",
    "phi3:medium"
  ],

  "model_families": {
    "qwen3": {
      "priority": 1,
      "reason": "Excellent JSON/structured output, agent-optimized",
      "sizes": ["0.6b", "1.7b", "4b", "8b", "14b", "32b", "30b-a3b"]
    },
    "qwen2.5": {
      "priority": 2,
      "reason": "Strong reasoning, good JSON support",
      "sizes": ["3b", "7b", "14b", "32b", "72b"]
    },
    "llama3.1": {
      "priority": 3,
      "reason": "Fast inference, large ecosystem",
      "sizes": ["8b", "70b"]
    },
    "gemma3": {
      "priority": 4,
      "reason": "Google's latest, efficient",
      "sizes": ["1b", "9b", "27b"]
    }
  },

  "deprecated_models": [
    "llama2:*",
    "mistral:7b-v0.1",
    "codellama:7b",
    "qwen:*"
  ],

  "upgrade_suggestions": {
    "llama3.2:3b": "qwen3:4b",
    "llama3.1:8b": "qwen3:8b",
    "qwen2.5:7b": "qwen3:8b",
    "qwen2.5:14b": "qwen3:14b",
    "mistral:7b": "qwen3:8b",
    "gemma2:9b": "gemma3:9b"
  }
}
